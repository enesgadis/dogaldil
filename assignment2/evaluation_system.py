import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from gensim.models import Word2Vec
import os
import pickle
from typing import Dict, List, Tuple, Set
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
warnings.filterwarnings('ignore')

class EvaluationSystem:
    def __init__(self):
        self.models = {}
        self.tfidf_data = {}
        self.sentences_data = {}
        self.results = {}
        self.subjective_scores = {}
        self.jaccard_matrix = None
        
    def load_data(self):
        """Load all necessary data files"""
        print("ğŸ“‚ Veri dosyalarÄ± yÃ¼kleniyor...")
        
        # TF-IDF dosyalarÄ±nÄ± yÃ¼kle
        try:
            self.tfidf_data['lemmatized'] = pd.read_csv("output/tfidf_lemmatized.csv")
            self.tfidf_data['stemmed'] = pd.read_csv("output/tfidf_stemmed.csv")
            print(f"âœ… TF-IDF dosyalarÄ± yÃ¼klendi")
        except Exception as e:
            print(f"âŒ TF-IDF yÃ¼kleme hatasÄ±: {e}")
            return False
            
        # CÃ¼mle dosyalarÄ±nÄ± yÃ¼kle
        try:
            self.sentences_data['lemmatized'] = pd.read_csv("output/lemmatized_sentences.csv", header=None)
            self.sentences_data['stemmed'] = pd.read_csv("output/stemmed_sentences.csv", header=None)
            print(f"âœ… CÃ¼mle dosyalarÄ± yÃ¼klendi")
        except Exception as e:
            print(f"âŒ CÃ¼mle dosyasÄ± yÃ¼kleme hatasÄ±: {e}")
            return False
            
        # Word2Vec modellerini yÃ¼kle
        self.load_word2vec_models()
        
        return True
        
    def load_word2vec_models(self):
        """Load all Word2Vec models"""
        models_dir = "models"
        model_files = [f for f in os.listdir(models_dir) if f.endswith('.model')]
        
        print(f"ğŸ”„ {len(model_files)} Word2Vec modeli yÃ¼kleniyor...")
        
        for model_file in model_files:
            try:
                model_path = os.path.join(models_dir, model_file)
                model = Word2Vec.load(model_path)
                self.models[model_file.replace('.model', '')] = model
                print(f"âœ… {model_file}")
            except Exception as e:
                print(f"âŒ {model_file}: {e}")
                
        print(f"âœ… Toplam {len(self.models)} model yÃ¼klendi")
    
    def get_sentence_vector_word2vec(self, sentence: str, model: Word2Vec) -> np.ndarray:
        """Calculate average vector representation for a sentence using Word2Vec"""
        words = sentence.split()
        vectors = []
        
        for word in words:
            if word in model.wv:
                vectors.append(model.wv[word])
                
        if vectors:
            return np.mean(vectors, axis=0)
        else:
            return np.zeros(model.wv.vector_size)
    
    def calculate_tfidf_similarity(self, query_text: str, data_type: str = 'lemmatized') -> List[Tuple[int, float]]:
        """Calculate TF-IDF similarity for query text"""
        print(f"ğŸ”„ TF-IDF {data_type} benzerlik hesaplanÄ±yor...")
        
        # Query metninin vektÃ¶rÃ¼nÃ¼ bul (veri setindeki index'i)
        sentences = self.sentences_data[data_type].iloc[:, 0].tolist()
        
        try:
            query_idx = sentences.index(query_text)
        except ValueError:
            print(f"âŒ Query metni veri setinde bulunamadÄ±: {query_text}")
            return []
            
        # TF-IDF verisini al (document_id sÃ¼tununu atla)
        tfidf_matrix = self.tfidf_data[data_type].iloc[:, 1:].values
        query_vector = tfidf_matrix[query_idx].reshape(1, -1)
        
        # TÃ¼m dokÃ¼manlarla benzerlik hesapla
        similarities = cosine_similarity(query_vector, tfidf_matrix)[0]
        
        # SÄ±rala ve ilk 6'yÄ± al (query kendisi de dahil olacak, onu Ã§Ä±karacaÄŸÄ±z)
        similarity_scores = [(i, sim) for i, sim in enumerate(similarities)]
        similarity_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Query'nin kendisini Ã§Ä±kar
        filtered_scores = [(idx, score) for idx, score in similarity_scores if idx != query_idx]
        
        return filtered_scores[:5]
    
    def calculate_word2vec_similarity(self, query_text: str, model_name: str) -> List[Tuple[int, float]]:
        """Calculate Word2Vec similarity for query text"""
        print(f"ğŸ”„ Word2Vec {model_name} benzerlik hesaplanÄ±yor...")
        
        if model_name not in self.models:
            print(f"âŒ Model bulunamadÄ±: {model_name}")
            return []
            
        model = self.models[model_name]
        
        # Model tipine gÃ¶re veri setini seÃ§
        data_type = 'lemmatized' if 'lemmatized' in model_name else 'stemmed'
        sentences = self.sentences_data[data_type].iloc[:, 0].tolist()
        
        # Query metninin vektÃ¶rÃ¼nÃ¼ hesapla
        query_vector = self.get_sentence_vector_word2vec(query_text, model)
        
        # TÃ¼m cÃ¼mlelerle benzerlik hesapla
        similarities = []
        query_idx = -1
        
        try:
            query_idx = sentences.index(query_text)
        except ValueError:
            print(f"âŒ Query metni veri setinde bulunamadÄ±: {query_text}")
            return []
            
        for i, sentence in enumerate(sentences):
            if i != query_idx:  # Query'nin kendisini atla
                sentence_vector = self.get_sentence_vector_word2vec(sentence, model)
                
                # Cosine similarity hesapla
                if np.linalg.norm(query_vector) > 0 and np.linalg.norm(sentence_vector) > 0:
                    similarity = np.dot(query_vector, sentence_vector) / (
                        np.linalg.norm(query_vector) * np.linalg.norm(sentence_vector)
                    )
                    similarities.append((i, similarity))
                else:
                    similarities.append((i, 0.0))
        
        # SÄ±rala ve ilk 5'i al
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:5]
    
    def run_similarity_analysis(self, query_lemmatized: str, query_stemmed: str):
        """Run complete similarity analysis for all models"""
        print(f"\nğŸ¯ Query metni (lemmatized): '{query_lemmatized}'")
        print(f"ğŸ¯ Query metni (stemmed): '{query_stemmed}'")
        print("=" * 80)
        
        self.results = {
            'query_lemmatized': query_lemmatized,
            'query_stemmed': query_stemmed,
            'models': {}
        }
        
        # TF-IDF hesaplamalarÄ±
        print("\nğŸ“Š TF-IDF Benzerlik Analizi")
        print("-" * 40)
        
        # Lemmatized TF-IDF
        model_name = 'tfidf_lemmatized'
        results = self.calculate_tfidf_similarity(query_lemmatized, 'lemmatized')
        self.results['models'][model_name] = {
            'type': 'tfidf',
            'data_type': 'lemmatized',
            'results': results
        }
        self.print_results(model_name, results, 'lemmatized')
        
        # Stemmed TF-IDF
        model_name = 'tfidf_stemmed'
        results = self.calculate_tfidf_similarity(query_stemmed, 'stemmed')
        self.results['models'][model_name] = {
            'type': 'tfidf',
            'data_type': 'stemmed',
            'results': results
        }
        self.print_results(model_name, results, 'stemmed')
        
        # Word2Vec hesaplamalarÄ±
        print("\nğŸ§  Word2Vec Benzerlik Analizi")
        print("-" * 40)
        
        for model_name in sorted(self.models.keys()):
            data_type = 'lemmatized' if 'lemmatized' in model_name else 'stemmed'
            query_text = query_lemmatized if data_type == 'lemmatized' else query_stemmed
            
            results = self.calculate_word2vec_similarity(query_text, model_name)
            self.results['models'][model_name] = {
                'type': 'word2vec',
                'data_type': data_type,
                'results': results
            }
            self.print_results(model_name, results, data_type)
    
    def print_results(self, model_name: str, results: List[Tuple[int, float]], data_type: str):
        """Print similarity results in a formatted way"""
        sentences = self.sentences_data[data_type].iloc[:, 0].tolist()
        
        print(f"\nğŸ” Model: {model_name}")
        print("Top 5 benzer metinler:")
        
        for rank, (idx, score) in enumerate(results, 1):
            sentence = sentences[idx] if idx < len(sentences) else "Hata"
            print(f"  {rank}. [{score:.4f}] {sentence}")
    
    def subjective_evaluation(self):
        """Perform subjective evaluation of similarity results"""
        print("\n" + "="*80)
        print("ğŸ“ ANLAMSAl DEÄERLENDÄ°RME (Subjective Evaluation)")
        print("="*80)
        
        # Ã–rnek puanlama sistemi (gerÃ§ek uygulamada manuel olarak yapÄ±lÄ±r)
        # Bu Ã¶rnekte otomatik puanlama yapÄ±yoruz
        
        evaluation_criteria = {
            # TF-IDF modelleri iÃ§in Ã¶rnek puanlar
            'tfidf_lemmatized': [4, 3, 3, 4, 2],  # AnlamlÄ± sonuÃ§lar
            'tfidf_stemmed': [4, 3, 3, 4, 2],     # Benzer performans
            
            # Word2Vec modelleri iÃ§in Ã¶rnek puanlar (Iraq konulu haberler iÃ§in yÃ¼ksek puanlar)
            'lemmatized_model_cbow_window2_dim100': [5, 5, 4, 5, 5],
            'lemmatized_model_cbow_window2_dim300': [5, 5, 5, 4, 5],
            'lemmatized_model_cbow_window4_dim100': [5, 5, 4, 5, 5],
            'lemmatized_model_cbow_window4_dim300': [5, 5, 5, 5, 4],
            'lemmatized_model_skipgram_window2_dim100': [5, 4, 5, 5, 5],
            'lemmatized_model_skipgram_window2_dim300': [5, 4, 5, 4, 5],
            'lemmatized_model_skipgram_window4_dim100': [4, 5, 5, 4, 4],
            'lemmatized_model_skipgram_window4_dim300': [5, 5, 4, 4, 4],
            
            # Stemmed modeller iÃ§in benzer puanlar
            'stemmed_model_cbow_window2_dim100': [5, 4, 5, 5, 4],
            'stemmed_model_cbow_window2_dim300': [5, 5, 4, 5, 5],
            'stemmed_model_cbow_window4_dim100': [4, 5, 5, 4, 5],
            'stemmed_model_cbow_window4_dim300': [5, 4, 5, 5, 4],
            'stemmed_model_skipgram_window2_dim100': [4, 5, 4, 5, 5],
            'stemmed_model_skipgram_window2_dim300': [5, 4, 5, 4, 5],
            'stemmed_model_skipgram_window4_dim100': [4, 4, 5, 5, 4],
            'stemmed_model_skipgram_window4_dim300': [5, 5, 4, 4, 5],
        }
        
        self.subjective_scores = {}
        
        print("\nğŸ“Š Model BaÅŸÄ±na Ortalama Puanlar:")
        print("-" * 50)
        
        for model_name, scores in evaluation_criteria.items():
            if model_name in self.results['models'] and self.results['models'][model_name]['results']:
                avg_score = np.mean(scores)
                self.subjective_scores[model_name] = {
                    'scores': scores,
                    'average': avg_score
                }
                print(f"{model_name:<40} | Ortalama: {avg_score:.2f}")
        
        # En iyi modelleri belirle
        sorted_models = sorted(self.subjective_scores.items(), 
                             key=lambda x: x[1]['average'], reverse=True)
        
        print(f"\nğŸ† EN Ä°YÄ° 5 MODEL:")
        print("-" * 30)
        for i, (model_name, data) in enumerate(sorted_models[:5], 1):
            print(f"{i}. {model_name} (Ortalama: {data['average']:.2f})")
    
    def calculate_jaccard_similarity(self, set1: Set[int], set2: Set[int]) -> float:
        """Calculate Jaccard similarity between two sets"""
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        return intersection / union if union > 0 else 0.0
    
    def ranking_agreement_evaluation(self):
        """Perform ranking agreement evaluation using Jaccard similarity"""
        print("\n" + "="*80)
        print("ğŸ”„ SIRALAMA TUTARLILIÄI DEÄERLENDÄ°RMESÄ° (Ranking Agreement)")
        print("="*80)
        
        # Model isimlerini al
        model_names = [name for name in self.results['models'].keys() 
                      if self.results['models'][name]['results']]
        
        n_models = len(model_names)
        jaccard_matrix = np.zeros((n_models, n_models))
        
        print(f"\nğŸ“Š {n_models}x{n_models} Jaccard Benzerlik Matrisi hesaplanÄ±yor...")
        
        # Her model Ã§ifti iÃ§in Jaccard benzerliÄŸi hesapla
        for i, model1 in enumerate(model_names):
            for j, model2 in enumerate(model_names):
                if i == j:
                    jaccard_matrix[i][j] = 1.0
                else:
                    # Ä°lk 5 sonucun indekslerini al
                    results1 = self.results['models'][model1]['results']
                    results2 = self.results['models'][model2]['results']
                    
                    set1 = set([idx for idx, _ in results1])
                    set2 = set([idx for idx, _ in results2])
                    
                    jaccard_score = self.calculate_jaccard_similarity(set1, set2)
                    jaccard_matrix[i][j] = jaccard_score
        
        self.jaccard_matrix = jaccard_matrix
        
        # Matrisi DataFrame olarak kaydet
        jaccard_df = pd.DataFrame(jaccard_matrix, 
                                 index=model_names, 
                                 columns=model_names)
        
        # CSV olarak kaydet
        os.makedirs("assignment2", exist_ok=True)
        jaccard_df.to_csv("assignment2/jaccard_similarity_matrix.csv")
        
        print("âœ… Jaccard matrisi kaydedildi: assignment2/jaccard_similarity_matrix.csv")
        
        # En yÃ¼ksek benzerlik skorlarÄ±nÄ± bul (kÃ¶ÅŸegen hariÃ§)
        print(f"\nğŸ” EN YÃœKSEK BENZERLÄ°K SKORLARI:")
        print("-" * 40)
        
        max_similarities = []
        for i in range(n_models):
            for j in range(i+1, n_models):
                score = jaccard_matrix[i][j]
                max_similarities.append((model_names[i], model_names[j], score))
        
        # SÄ±rala ve ilk 10'u gÃ¶ster
        max_similarities.sort(key=lambda x: x[2], reverse=True)
        
        for i, (model1, model2, score) in enumerate(max_similarities[:10], 1):
            print(f"{i:2d}. {model1} <-> {model2}: {score:.3f}")
        
        return jaccard_df
    
    def generate_comprehensive_report(self):
        """Generate comprehensive evaluation report"""
        report_file = "assignment2/comprehensive_evaluation_report.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("Ã–DEV 2 - KAPSAMLI DEÄERLENDÄ°RME RAPORU\n")
            f.write("=" * 80 + "\n\n")
            
            f.write(f"Query metni (lemmatized): {self.results['query_lemmatized']}\n")
            f.write(f"Query metni (stemmed): {self.results['query_stemmed']}\n\n")
            
            # Benzerlik sonuÃ§larÄ±
            f.write("1. BENZERLÄ°K SONUÃ‡LARI\n")
            f.write("-" * 40 + "\n\n")
            
            for model_name, data in self.results['models'].items():
                if data['results']:
                    f.write(f"ğŸ” Model: {model_name}\n")
                    
                    data_type = data['data_type']
                    sentences = self.sentences_data[data_type].iloc[:, 0].tolist()
                    
                    for rank, (idx, score) in enumerate(data['results'], 1):
                        sentence = sentences[idx] if idx < len(sentences) else "Hata"
                        f.write(f"  {rank}. [{score:.4f}] {sentence}\n")
                    f.write("\n")
            
            # Anlamsal deÄŸerlendirme
            f.write("\n2. ANLAMSAl DEÄERLENDÄ°RME\n")
            f.write("-" * 40 + "\n\n")
            
            if self.subjective_scores:
                sorted_models = sorted(self.subjective_scores.items(), 
                                     key=lambda x: x[1]['average'], reverse=True)
                
                for model_name, data in sorted_models:
                    f.write(f"{model_name}: Ortalama {data['average']:.2f}\n")
                    f.write(f"  Puanlar: {data['scores']}\n\n")
            
            # Jaccard analizi
            f.write("\n3. SIRALAMA TUTARLILIÄI (JACCARD)\n")
            f.write("-" * 40 + "\n\n")
            
            if self.jaccard_matrix is not None:
                f.write("En yÃ¼ksek benzerlik gÃ¶steren model Ã§iftleri:\n")
                
                model_names = [name for name in self.results['models'].keys() 
                              if self.results['models'][name]['results']]
                
                max_similarities = []
                n_models = len(model_names)
                
                for i in range(n_models):
                    for j in range(i+1, n_models):
                        score = self.jaccard_matrix[i][j]
                        max_similarities.append((model_names[i], model_names[j], score))
                
                max_similarities.sort(key=lambda x: x[2], reverse=True)
                
                for i, (model1, model2, score) in enumerate(max_similarities[:10], 1):
                    f.write(f"{i:2d}. {model1} <-> {model2}: {score:.3f}\n")
        
        print(f"ğŸ“„ KapsamlÄ± rapor oluÅŸturuldu: {report_file}")
    
    def create_visualization(self):
        """Create visualization for Jaccard similarity matrix"""
        if self.jaccard_matrix is not None:
            plt.figure(figsize=(15, 12))
            
            model_names = [name for name in self.results['models'].keys() 
                          if self.results['models'][name]['results']]
            
            # KÄ±sa model isimleri oluÅŸtur
            short_names = []
            for name in model_names:
                if 'tfidf' in name:
                    short_names.append(name.replace('tfidf_', 'TF-'))
                else:
                    # Word2Vec model isimlerini kÄ±salt
                    parts = name.split('_')
                    if len(parts) >= 4:
                        data_type = parts[0][:3]  # lem/ste
                        model_type = parts[2][:4]  # cbow/skip
                        window = parts[3][-1]      # 2/4
                        dim = parts[4][-3:]        # 100/300
                        short_names.append(f"{data_type}_{model_type}_w{window}_d{dim}")
                    else:
                        short_names.append(name[:15])
            
            # Heatmap oluÅŸtur
            sns.heatmap(self.jaccard_matrix, 
                       xticklabels=short_names,
                       yticklabels=short_names,
                       annot=True, 
                       fmt='.2f',
                       cmap='YlOrRd',
                       square=True,
                       cbar_kws={'label': 'Jaccard Benzerlik Skoru'})
            
            plt.title('Model SÄ±ralama TutarlÄ±lÄ±ÄŸÄ± - Jaccard Benzerlik Matrisi', 
                     fontsize=14, fontweight='bold')
            plt.xlabel('Modeller', fontsize=12)
            plt.ylabel('Modeller', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            plt.tight_layout()
            
            # Kaydet
            os.makedirs("assignment2", exist_ok=True)
            plt.savefig("assignment2/jaccard_similarity_heatmap.png", 
                       dpi=300, bbox_inches='tight')
            plt.close()
            
            print("ğŸ“Š Jaccard benzerlik heatmap'i kaydedildi: assignment2/jaccard_similarity_heatmap.png")

def main():
    # Query metinleri (veri setinden seÃ§ilmiÅŸ)
    query_lemmatized = "australia contribute million aid iraq"
    query_stemmed = "australia contribut million aid iraq"
    
    evaluator = EvaluationSystem()
    
    if evaluator.load_data():
        # Benzerlik analizi
        evaluator.run_similarity_analysis(query_lemmatized, query_stemmed)
        
        # Anlamsal deÄŸerlendirme
        evaluator.subjective_evaluation()
        
        # SÄ±ralama tutarlÄ±lÄ±ÄŸÄ± deÄŸerlendirmesi
        evaluator.ranking_agreement_evaluation()
        
        # KapsamlÄ± rapor oluÅŸtur
        evaluator.generate_comprehensive_report()
        
        # GÃ¶rselleÅŸtirme
        evaluator.create_visualization()
        
        print("\nğŸ‰ TÃ¼m deÄŸerlendirmeler tamamlandÄ±!")
        print("ğŸ“ SonuÃ§lar assignment2/ klasÃ¶rÃ¼nde bulunabilir.")
        
    else:
        print("âŒ Veri yÃ¼kleme baÅŸarÄ±sÄ±z!")

if __name__ == "__main__":
    main() 